Technique used to `improve the performance` of application by fetching the most frequently accessed data in a ver ver fast response time and `reducing the load` on original database by using the temporary data(also called in-memory database)

## How Caching works
1. `Cache check` system first checks in cache whether the requested data is available or not.
2. `Cache Hit` If the data is found in the cache, it's a "cache hit," and the data is retrieved immediately from the high-speed cache, which is very fast (often using RAM).
3. `Cache Miss` If the data is not found, it's a "cache miss". The system then fetches the data from its original database.
4. `Cache Population` Before returning the response to the user, data will get save in cache first, if same data will be requested then it'll be cache hit case.


Because caches have a limited capacity, they use eviction policies such as Least Recently Used (LRU).

## Benefits of Caching
1. `Improved Performance`: Significantly reduces the time it takes to access data (lower latency).
2. `Reduced Load`: Decreases the demand and processing burden on backend servers and databases.
3. `Increased Throughput`: Allows systems to handle a higher volume of requests per second.
4. `Cost Efficiency`: Can reduce the need for expensive hardware upgrades or overprovisioning of database resources.
5. `Enhanced Scalability`: Helps applications scale more efficiently by distributing the data access load. 